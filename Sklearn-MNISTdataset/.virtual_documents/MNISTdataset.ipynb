import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import tensorflow as tf
import tensorflow.keras as keras


import warnings
warnings.filterwarnings('ignore')





# train_data, test_data= tf.keras.datasets.mnist.load_data()


with np.load('mnist.npz') as data:
    X_train = data['x_train']
    y_train = data['y_train']
    X_test = data['x_test']
    y_test = data['y_test']


plt.imshow(X_train[85], cmap= 'gray_r')
plt.title(f'target: {y_train[85]}')
plt.xticks([])
plt.yticks([])
plt.tight_layout()


fig, axes= plt.subplots(nrows=4 , ncols=6 , figsize=(9,6))
for item in zip(axes.ravel(), X_train, y_train):
    ax, image, target= item
    ax.imshow(image, cmap= 'gray_r')
    ax.set_title(f'Label: {target}')
    ax.axis('off')
plt.tight_layout()





imput_layer= keras.layers.Input(shape=(28,28))
flatten_layer= keras.layers.Flatten()(imput_layer)
hidden_layer1= keras.layers.Dense(128, activation= 'relu')(flatten_layer)
hidden_layer2= keras.layers.Dense(256, activation= 'relu')(hidden_layer1)
output_layer= keras.layers.Dense(10,activation= 'softmax')(hidden_layer2)

model=keras.Model(imput_layer, output_layer)
model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train,y_train)
print(model.summary())

test_loss, test_acc= model.evaluate(X_test,y_test)
print(f" test loss: {test_loss}")
print(f" test accuracy: {test_acc}")


imput_layer= keras.layers.Input(shape=(28,28))
flatten_layer= keras.layers.Flatten()(imput_layer)
hidden_layer1= keras.layers.Dense(128, activation= 'relu')(flatten_layer)
hidden_layer2= keras.layers.Dense(256, activation= 'relu')(hidden_layer1)
output_layer= keras.layers.Dense(10,activation= 'softmax')(hidden_layer2)

model=keras.Model(imput_layer, output_layer)
model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics=['accuracy'])

model.fit(X_train,y_train, epochs=10, batch_size=32)
#print(model.summary())

test_loss, test_acc= model.evaluate(X_test,y_test)
print(f" test loss: {test_loss}")
print(f" test accuracy: {test_acc}")


input_layer = keras.layers.Input(shape= (28, 28))
flat_layer = keras.layers.Flatten()(input_layer)
hidden_layer1 = keras.layers.Dense(128, activation = 'relu')(flat_layer)
hidden_layer2 = keras.layers.Dense(256, activation = 'relu')(hidden_layer1)
output_layer = keras.layers.Dense(10, activation = 'softmax')(hidden_layer2)

model= keras.Model(input_layer, output_layer)
# optimizer= ['adam', 'rmsprop', 'sgd']
# Or from tensorflow.keras.optimizers import SGD
# optimizer = SGD(learning_rate=0.01, momentum=0.9)
# loss= ['mean_squared_error', 'mean_absolute_error', 'huber_loss', 'mean_squared_logarithmic_error'] regression
# loss= ['binary_crossentropy', 'sparse_categorical_crossentropy', 'categorical_crossentropy'] classification
# metrics=['mse', 'mse'] regression
### clasification metrics?
# Accuracy metrics
# metrics=['accuracy']  # Auto-detects binary/multi-class
# metrics=['binary_accuracy']  # For binary classification
# metrics=['categorical_accuracy']  # For one-hot encoded multi-class
# metrics=['sparse_categorical_accuracy']  # For integer labels multi-class
# metrics=['top_k_categorical_accuracy']  # Top-k accuracy
# metrics=['sparse_top_k_categorical_accuracy']  # Top-k with integer labels

# # Precision/Recall/F1
# metrics=['precision']  # For binary
# metrics=['recall']  # For binary  
# metrics=['auc']  # Area Under ROC Curve
# metrics=['prc'] or metrics=['precision_at_recall']  # Precision-Recall Curve

model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics=['sparse_categorical_accuracy'])
model.fit(X_train, y_train, epochs= 10, batch_size= 32)





X_all= np.concatenate((X_train, X_test), axis=0)
y_all= np.concatenate((y_train, y_test), axis=0)


X_flat= X_all.reshape(X_all.shape[0], -1)


X_flat.shape


data_csv= np.hstack((X_flat, y_all.reshape(-1, 1)))


df= pd.DataFrame(data_csv)
#df.to_csv('mnist_dataset.csv', index=False, header=True)


df.info()





data= pd.read_csv('E:\Python Projects\shohreh\Shohreh_GitHub_Repository\Deep-learning-projects\Sklearn-MNISTdataset/mnist_dataset.csv')


from sklearn.model_selection import train_test_split
X=data.drop('784', axis=1)
y= data['784']

X_train, X_test, y_train, y_test= train_test_split(X, y, train_size=.8, random_state= 42)

# Normalize pixel values to [0,1]
X_train = X_train.astype('float32') / 255.0
X_test = X_test.astype('float32') / 255.0


image= X.iloc[36].values.reshape(28,28)
plt.imshow(image, cmap= 'gray_r')
plt.title(f'target: {y.iloc[36]}')
plt.xticks([])
plt.yticks([])
plt.tight_layout()


from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score
import tensorflow as tf
from tensorflow import keras
# from tensorflow.keras import layers

layer1 = keras.layers.Dense(300, activation= 'relu', input_shape= (X_train.shape[1],))
layer2 = keras.layers.Dense(100, activation= 'relu')
layer3 = keras.layers.Dense(10, activation= 'softmax')
dnn_model = keras.Sequential([layer1, layer2, layer3])
dnn_model.compile(optimizer= 'adam', loss= 'sparse_categorical_crossentropy', metrics= ['accuracy'])
history = dnn_model.fit(X_train, y_train, batch_size=5, epochs= 5, validation_data= (X_test, y_test)) # epochs= 40000 // (len(X_train) // 50)
test_loss, test_accuracy = dnn_model.evaluate(X_test, y_test)
y_pred = dnn_model.predict(X_test)
y_pred_classes = tf.argmax(y_pred, axis=1)



