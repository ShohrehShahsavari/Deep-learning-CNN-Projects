{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1686de0a-427d-4bdf-be89-d63e1bd80255",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras as layers\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "housing= fetch_california_housing()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "279f0022-435b-45d4-8271-c7c553b01f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.DataFrame(housing.data)\n",
    "y = pd.DataFrame(housing.target)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "y = scaler.fit_transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split (X, y, train_size= .8, random_state= 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "47b4ea7f-194e-4072-8190-a5ed32f75991",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.3736 - mae: 0.4263 - val_loss: 0.3012 - val_mae: 0.3900\n",
      "Epoch 2/50\n",
      "331/331 [==============================] - 0s 2ms/step - loss: 0.4141 - mae: 0.3820 - val_loss: 0.2681 - val_mae: 0.3748\n",
      "Epoch 3/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2704 - mae: 0.3533 - val_loss: 0.2491 - val_mae: 0.3485\n",
      "Epoch 4/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2374 - mae: 0.3409 - val_loss: 0.2379 - val_mae: 0.3345\n",
      "Epoch 5/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2277 - mae: 0.3324 - val_loss: 0.2473 - val_mae: 0.3535\n",
      "Epoch 6/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2231 - mae: 0.3280 - val_loss: 0.2382 - val_mae: 0.3468\n",
      "Epoch 7/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2186 - mae: 0.3240 - val_loss: 0.2414 - val_mae: 0.3551\n",
      "Epoch 8/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2160 - mae: 0.3216 - val_loss: 0.2193 - val_mae: 0.3240\n",
      "Epoch 9/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2110 - mae: 0.3165 - val_loss: 0.2159 - val_mae: 0.3174\n",
      "Epoch 10/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2116 - mae: 0.3177 - val_loss: 0.2133 - val_mae: 0.3189\n",
      "Epoch 11/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2081 - mae: 0.3127 - val_loss: 0.2164 - val_mae: 0.3242\n",
      "Epoch 12/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2052 - mae: 0.3108 - val_loss: 0.2164 - val_mae: 0.3144\n",
      "Epoch 13/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2025 - mae: 0.3085 - val_loss: 0.2091 - val_mae: 0.3151\n",
      "Epoch 14/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2012 - mae: 0.3076 - val_loss: 0.2108 - val_mae: 0.3203\n",
      "Epoch 15/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2007 - mae: 0.3055 - val_loss: 0.2129 - val_mae: 0.3138\n",
      "Epoch 16/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1985 - mae: 0.3051 - val_loss: 0.2096 - val_mae: 0.3081\n",
      "Epoch 17/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1951 - mae: 0.3020 - val_loss: 0.2118 - val_mae: 0.3106\n",
      "Epoch 18/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1951 - mae: 0.3015 - val_loss: 0.2083 - val_mae: 0.3031\n",
      "Epoch 19/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1919 - mae: 0.2996 - val_loss: 0.2079 - val_mae: 0.3160\n",
      "Epoch 20/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1908 - mae: 0.2979 - val_loss: 0.2078 - val_mae: 0.3018\n",
      "Epoch 21/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1898 - mae: 0.2972 - val_loss: 0.2134 - val_mae: 0.3215\n",
      "Epoch 22/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1895 - mae: 0.2985 - val_loss: 0.2056 - val_mae: 0.3123\n",
      "Epoch 23/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1866 - mae: 0.2944 - val_loss: 0.2038 - val_mae: 0.3094\n",
      "Epoch 24/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1833 - mae: 0.2918 - val_loss: 0.2054 - val_mae: 0.3088\n",
      "Epoch 25/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1815 - mae: 0.2907 - val_loss: 0.2023 - val_mae: 0.3058\n",
      "Epoch 26/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1806 - mae: 0.2905 - val_loss: 0.2066 - val_mae: 0.3009\n",
      "Epoch 27/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1804 - mae: 0.2887 - val_loss: 0.2096 - val_mae: 0.3077\n",
      "Epoch 28/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1814 - mae: 0.2903 - val_loss: 0.2067 - val_mae: 0.2996\n",
      "Epoch 29/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1790 - mae: 0.2885 - val_loss: 0.2007 - val_mae: 0.2998\n",
      "Epoch 30/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1772 - mae: 0.2867 - val_loss: 0.1980 - val_mae: 0.2992\n",
      "Epoch 31/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1766 - mae: 0.2848 - val_loss: 0.1969 - val_mae: 0.3011\n",
      "Epoch 32/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1742 - mae: 0.2835 - val_loss: 0.2015 - val_mae: 0.3105\n",
      "Epoch 33/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1733 - mae: 0.2837 - val_loss: 0.2101 - val_mae: 0.3020\n",
      "Epoch 34/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1726 - mae: 0.2821 - val_loss: 0.1991 - val_mae: 0.2990\n",
      "Epoch 35/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1730 - mae: 0.2837 - val_loss: 0.2036 - val_mae: 0.3016\n",
      "Epoch 36/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1790 - mae: 0.2799 - val_loss: 0.1984 - val_mae: 0.3036\n",
      "Epoch 37/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1721 - mae: 0.2818 - val_loss: 0.2041 - val_mae: 0.3075\n",
      "Epoch 38/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1682 - mae: 0.2794 - val_loss: 0.2112 - val_mae: 0.3151\n",
      "Epoch 39/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1671 - mae: 0.2785 - val_loss: 0.1988 - val_mae: 0.2952\n",
      "Epoch 40/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1659 - mae: 0.2786 - val_loss: 0.1992 - val_mae: 0.3017\n",
      "Epoch 41/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1639 - mae: 0.2757 - val_loss: 0.2061 - val_mae: 0.3116\n",
      "Epoch 42/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1629 - mae: 0.2750 - val_loss: 0.2050 - val_mae: 0.3091\n",
      "Epoch 43/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1622 - mae: 0.2740 - val_loss: 0.1929 - val_mae: 0.2893\n",
      "Epoch 44/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1601 - mae: 0.2724 - val_loss: 0.1943 - val_mae: 0.2993\n",
      "Epoch 45/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1609 - mae: 0.2735 - val_loss: 0.1945 - val_mae: 0.2920\n",
      "Epoch 46/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1594 - mae: 0.2733 - val_loss: 0.2064 - val_mae: 0.3016\n",
      "Epoch 47/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1610 - mae: 0.2741 - val_loss: 0.1969 - val_mae: 0.3054\n",
      "Epoch 48/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1565 - mae: 0.2701 - val_loss: 0.1942 - val_mae: 0.2917\n",
      "Epoch 49/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1564 - mae: 0.2695 - val_loss: 0.1951 - val_mae: 0.2943\n",
      "Epoch 50/50\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1544 - mae: 0.2678 - val_loss: 0.1961 - val_mae: 0.2931\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "layer1 = layers.Dense(300, activation= 'relu', input_shape= (housing.data.shape[1],))\n",
    "layer2 = layers.Dense(100, activation= 'relu')\n",
    "layer3 = layers.Dense(1)\n",
    "\n",
    "dnn_model = keras.Sequential([layer1, layer2, layer3])\n",
    "# optimizer= ['adam', 'rmsprop', 'sgd']\n",
    "# Or from tensorflow.keras.optimizers import SGD\n",
    "# optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "# loss= ['mean_squared_error', 'mean_absolute_error', 'huber_loss', 'mean_squared_logarithmic_error']\n",
    "# metrics=['mse', 'mse']\n",
    "dnn_model.compile(optimizer= 'adam',loss= 'mean_squared_error', metrics=['mae']) \n",
    "history = dnn_model.fit(X_train, y_train, epochs= 50, batch_size= 50, validation_data = (X_test, y_test)) #40000 // (len(X_train) // 50), batch_size= 50, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4907569b-2629-40a1-837f-73dba41b80a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129/129 [==============================] - 0s 1ms/step - loss: 0.1961 - mae: 0.2931\n",
      "129/129 [==============================] - 0s 767us/step\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_mse = dnn_model.evaluate(X_test, y_test)\n",
    "y_pred = dnn_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "573338e2-bbdc-431c-8d11-87b88a6cb978",
   "metadata": {},
   "source": [
    "# Implementing Batch Normalization with TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0431dca4-c6a4-43a2-abca-ef17eb8266b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/121\n",
      "331/331 [==============================] - 2s 3ms/step - loss: 0.3772 - mae: 0.4447 - val_loss: 0.3688 - val_mae: 0.4271\n",
      "Epoch 2/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2927 - mae: 0.3907 - val_loss: 0.3980 - val_mae: 0.4074\n",
      "Epoch 3/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2777 - mae: 0.3786 - val_loss: 0.4187 - val_mae: 0.4145\n",
      "Epoch 4/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2713 - mae: 0.3722 - val_loss: 0.4281 - val_mae: 0.4235\n",
      "Epoch 5/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2585 - mae: 0.3615 - val_loss: 0.3985 - val_mae: 0.4020\n",
      "Epoch 6/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2610 - mae: 0.3630 - val_loss: 0.3752 - val_mae: 0.3982\n",
      "Epoch 7/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2588 - mae: 0.3629 - val_loss: 0.3796 - val_mae: 0.4008\n",
      "Epoch 8/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2501 - mae: 0.3542 - val_loss: 0.3549 - val_mae: 0.3876\n",
      "Epoch 9/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2482 - mae: 0.3509 - val_loss: 0.4184 - val_mae: 0.4199\n",
      "Epoch 10/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2482 - mae: 0.3514 - val_loss: 0.4745 - val_mae: 0.4428\n",
      "Epoch 11/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2387 - mae: 0.3457 - val_loss: 0.4122 - val_mae: 0.4162\n",
      "Epoch 12/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2415 - mae: 0.3458 - val_loss: 0.3234 - val_mae: 0.3852\n",
      "Epoch 13/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2397 - mae: 0.3444 - val_loss: 0.3812 - val_mae: 0.4117\n",
      "Epoch 14/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2408 - mae: 0.3470 - val_loss: 0.3603 - val_mae: 0.3836\n",
      "Epoch 15/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2386 - mae: 0.3439 - val_loss: 0.3554 - val_mae: 0.3974\n",
      "Epoch 16/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2343 - mae: 0.3401 - val_loss: 0.3741 - val_mae: 0.3925\n",
      "Epoch 17/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2354 - mae: 0.3405 - val_loss: 0.3325 - val_mae: 0.3957\n",
      "Epoch 18/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2370 - mae: 0.3411 - val_loss: 0.3113 - val_mae: 0.3639\n",
      "Epoch 19/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2325 - mae: 0.3385 - val_loss: 0.3656 - val_mae: 0.3915\n",
      "Epoch 20/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2314 - mae: 0.3375 - val_loss: 0.4430 - val_mae: 0.4467\n",
      "Epoch 21/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2260 - mae: 0.3328 - val_loss: 0.4207 - val_mae: 0.4137\n",
      "Epoch 22/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2324 - mae: 0.3384 - val_loss: 0.3972 - val_mae: 0.4067\n",
      "Epoch 23/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2272 - mae: 0.3339 - val_loss: 0.3534 - val_mae: 0.3777\n",
      "Epoch 24/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2305 - mae: 0.3341 - val_loss: 0.3674 - val_mae: 0.4026\n",
      "Epoch 25/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2264 - mae: 0.3333 - val_loss: 0.4059 - val_mae: 0.4241\n",
      "Epoch 26/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2254 - mae: 0.3341 - val_loss: 0.4118 - val_mae: 0.4158\n",
      "Epoch 27/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2241 - mae: 0.3316 - val_loss: 0.4020 - val_mae: 0.4116\n",
      "Epoch 28/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2244 - mae: 0.3323 - val_loss: 0.3427 - val_mae: 0.3780\n",
      "Epoch 29/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2226 - mae: 0.3303 - val_loss: 0.3311 - val_mae: 0.3719\n",
      "Epoch 30/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2279 - mae: 0.3335 - val_loss: 0.3827 - val_mae: 0.4013\n",
      "Epoch 31/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2204 - mae: 0.3296 - val_loss: 0.4828 - val_mae: 0.4618\n",
      "Epoch 32/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2222 - mae: 0.3309 - val_loss: 0.3809 - val_mae: 0.4009\n",
      "Epoch 33/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2245 - mae: 0.3333 - val_loss: 0.4943 - val_mae: 0.4619\n",
      "Epoch 34/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2205 - mae: 0.3293 - val_loss: 0.4466 - val_mae: 0.4361\n",
      "Epoch 35/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2200 - mae: 0.3279 - val_loss: 0.4094 - val_mae: 0.4164\n",
      "Epoch 36/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2224 - mae: 0.3300 - val_loss: 0.4094 - val_mae: 0.4214\n",
      "Epoch 37/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2165 - mae: 0.3245 - val_loss: 0.4304 - val_mae: 0.4246\n",
      "Epoch 38/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2197 - mae: 0.3279 - val_loss: 0.3681 - val_mae: 0.3948\n",
      "Epoch 39/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2155 - mae: 0.3251 - val_loss: 0.4466 - val_mae: 0.4353\n",
      "Epoch 40/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2162 - mae: 0.3262 - val_loss: 0.4613 - val_mae: 0.4476\n",
      "Epoch 41/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2181 - mae: 0.3270 - val_loss: 0.3802 - val_mae: 0.4014\n",
      "Epoch 42/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2133 - mae: 0.3222 - val_loss: 0.4375 - val_mae: 0.4300\n",
      "Epoch 43/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2143 - mae: 0.3238 - val_loss: 0.3882 - val_mae: 0.4140\n",
      "Epoch 44/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2128 - mae: 0.3228 - val_loss: 0.4155 - val_mae: 0.4257\n",
      "Epoch 45/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2097 - mae: 0.3208 - val_loss: 0.4051 - val_mae: 0.4169\n",
      "Epoch 46/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2116 - mae: 0.3204 - val_loss: 0.3749 - val_mae: 0.4004\n",
      "Epoch 47/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2102 - mae: 0.3218 - val_loss: 0.3682 - val_mae: 0.4090\n",
      "Epoch 48/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2172 - mae: 0.3287 - val_loss: 0.4199 - val_mae: 0.4194\n",
      "Epoch 49/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2109 - mae: 0.3207 - val_loss: 0.4224 - val_mae: 0.4393\n",
      "Epoch 50/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2097 - mae: 0.3197 - val_loss: 0.4043 - val_mae: 0.4105\n",
      "Epoch 51/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2082 - mae: 0.3195 - val_loss: 0.4358 - val_mae: 0.4413\n",
      "Epoch 52/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2072 - mae: 0.3188 - val_loss: 0.4141 - val_mae: 0.4166\n",
      "Epoch 53/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2079 - mae: 0.3165 - val_loss: 0.4112 - val_mae: 0.4265\n",
      "Epoch 54/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2085 - mae: 0.3205 - val_loss: 0.4923 - val_mae: 0.4603\n",
      "Epoch 55/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2082 - mae: 0.3180 - val_loss: 0.3684 - val_mae: 0.3915\n",
      "Epoch 56/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2081 - mae: 0.3196 - val_loss: 0.4770 - val_mae: 0.4677\n",
      "Epoch 57/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2086 - mae: 0.3195 - val_loss: 0.4273 - val_mae: 0.4273\n",
      "Epoch 58/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2060 - mae: 0.3165 - val_loss: 0.4435 - val_mae: 0.4370\n",
      "Epoch 59/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2063 - mae: 0.3171 - val_loss: 0.4338 - val_mae: 0.4304\n",
      "Epoch 60/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2082 - mae: 0.3192 - val_loss: 0.4084 - val_mae: 0.4205\n",
      "Epoch 61/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2053 - mae: 0.3171 - val_loss: 0.3827 - val_mae: 0.4063\n",
      "Epoch 62/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2013 - mae: 0.3133 - val_loss: 0.3989 - val_mae: 0.4100\n",
      "Epoch 63/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2060 - mae: 0.3164 - val_loss: 0.3731 - val_mae: 0.3958\n",
      "Epoch 64/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2031 - mae: 0.3166 - val_loss: 0.3695 - val_mae: 0.4057\n",
      "Epoch 65/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2039 - mae: 0.3161 - val_loss: 0.4432 - val_mae: 0.4424\n",
      "Epoch 66/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2039 - mae: 0.3163 - val_loss: 0.4536 - val_mae: 0.4478\n",
      "Epoch 67/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2042 - mae: 0.3152 - val_loss: 0.3927 - val_mae: 0.4117\n",
      "Epoch 68/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1998 - mae: 0.3119 - val_loss: 0.3985 - val_mae: 0.4066\n",
      "Epoch 69/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2043 - mae: 0.3157 - val_loss: 0.4371 - val_mae: 0.4290\n",
      "Epoch 70/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2027 - mae: 0.3169 - val_loss: 0.3749 - val_mae: 0.4042\n",
      "Epoch 71/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2018 - mae: 0.3148 - val_loss: 0.3565 - val_mae: 0.3857\n",
      "Epoch 72/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2005 - mae: 0.3111 - val_loss: 0.4241 - val_mae: 0.4238\n",
      "Epoch 73/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1983 - mae: 0.3121 - val_loss: 0.3824 - val_mae: 0.3983\n",
      "Epoch 74/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1978 - mae: 0.3111 - val_loss: 0.4365 - val_mae: 0.4427\n",
      "Epoch 75/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1979 - mae: 0.3113 - val_loss: 0.3984 - val_mae: 0.4166\n",
      "Epoch 76/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2007 - mae: 0.3135 - val_loss: 0.3586 - val_mae: 0.3962\n",
      "Epoch 77/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1973 - mae: 0.3097 - val_loss: 0.3658 - val_mae: 0.3919\n",
      "Epoch 78/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1998 - mae: 0.3119 - val_loss: 0.3776 - val_mae: 0.4079\n",
      "Epoch 79/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2009 - mae: 0.3144 - val_loss: 0.4227 - val_mae: 0.4301\n",
      "Epoch 80/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.2013 - mae: 0.3141 - val_loss: 0.4299 - val_mae: 0.4310\n",
      "Epoch 81/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1984 - mae: 0.3119 - val_loss: 0.4620 - val_mae: 0.4582\n",
      "Epoch 82/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1983 - mae: 0.3109 - val_loss: 0.4467 - val_mae: 0.4420\n",
      "Epoch 83/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1949 - mae: 0.3080 - val_loss: 0.3804 - val_mae: 0.4086\n",
      "Epoch 84/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1956 - mae: 0.3088 - val_loss: 0.4161 - val_mae: 0.4216\n",
      "Epoch 85/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1990 - mae: 0.3119 - val_loss: 0.4378 - val_mae: 0.4309\n",
      "Epoch 86/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1939 - mae: 0.3069 - val_loss: 0.4341 - val_mae: 0.4369\n",
      "Epoch 87/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1951 - mae: 0.3085 - val_loss: 0.4301 - val_mae: 0.4334\n",
      "Epoch 88/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1955 - mae: 0.3098 - val_loss: 0.5067 - val_mae: 0.4678\n",
      "Epoch 89/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1966 - mae: 0.3092 - val_loss: 0.4182 - val_mae: 0.4410\n",
      "Epoch 90/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1964 - mae: 0.3101 - val_loss: 0.4273 - val_mae: 0.4377\n",
      "Epoch 91/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1943 - mae: 0.3060 - val_loss: 0.4402 - val_mae: 0.4343\n",
      "Epoch 92/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1970 - mae: 0.3103 - val_loss: 0.4778 - val_mae: 0.4565\n",
      "Epoch 93/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1947 - mae: 0.3067 - val_loss: 0.4212 - val_mae: 0.4255\n",
      "Epoch 94/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1926 - mae: 0.3059 - val_loss: 0.4349 - val_mae: 0.4384\n",
      "Epoch 95/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1964 - mae: 0.3094 - val_loss: 0.3815 - val_mae: 0.4032\n",
      "Epoch 96/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1903 - mae: 0.3047 - val_loss: 0.3673 - val_mae: 0.4021\n",
      "Epoch 97/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1920 - mae: 0.3056 - val_loss: 0.4129 - val_mae: 0.4359\n",
      "Epoch 98/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1931 - mae: 0.3071 - val_loss: 0.4464 - val_mae: 0.4351\n",
      "Epoch 99/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1935 - mae: 0.3071 - val_loss: 0.4311 - val_mae: 0.4306\n",
      "Epoch 100/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1974 - mae: 0.3113 - val_loss: 0.4310 - val_mae: 0.4355\n",
      "Epoch 101/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1916 - mae: 0.3051 - val_loss: 0.4425 - val_mae: 0.4336\n",
      "Epoch 102/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1939 - mae: 0.3090 - val_loss: 0.4090 - val_mae: 0.4219\n",
      "Epoch 103/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1934 - mae: 0.3076 - val_loss: 0.4148 - val_mae: 0.4225\n",
      "Epoch 104/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1916 - mae: 0.3052 - val_loss: 0.4435 - val_mae: 0.4406\n",
      "Epoch 105/121\n",
      "331/331 [==============================] - 1s 2ms/step - loss: 0.1901 - mae: 0.3046 - val_loss: 0.4967 - val_mae: 0.4660\n",
      "Epoch 106/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1937 - mae: 0.3067 - val_loss: 0.4134 - val_mae: 0.4271\n",
      "Epoch 107/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1916 - mae: 0.3061 - val_loss: 0.5192 - val_mae: 0.4766\n",
      "Epoch 108/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1903 - mae: 0.3038 - val_loss: 0.4523 - val_mae: 0.4473\n",
      "Epoch 109/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1923 - mae: 0.3061 - val_loss: 0.4735 - val_mae: 0.4591\n",
      "Epoch 110/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1911 - mae: 0.3054 - val_loss: 0.4617 - val_mae: 0.4501\n",
      "Epoch 111/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1900 - mae: 0.3049 - val_loss: 0.4334 - val_mae: 0.4276\n",
      "Epoch 112/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1872 - mae: 0.3026 - val_loss: 0.4283 - val_mae: 0.4293\n",
      "Epoch 113/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1917 - mae: 0.3066 - val_loss: 0.4139 - val_mae: 0.4237\n",
      "Epoch 114/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1886 - mae: 0.3040 - val_loss: 0.4461 - val_mae: 0.4478\n",
      "Epoch 115/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1866 - mae: 0.3035 - val_loss: 0.4570 - val_mae: 0.4471\n",
      "Epoch 116/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1885 - mae: 0.3029 - val_loss: 0.4695 - val_mae: 0.4485\n",
      "Epoch 117/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1885 - mae: 0.3035 - val_loss: 0.4717 - val_mae: 0.4540\n",
      "Epoch 118/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1897 - mae: 0.3046 - val_loss: 0.4265 - val_mae: 0.4255\n",
      "Epoch 119/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1898 - mae: 0.3060 - val_loss: 0.3971 - val_mae: 0.4085\n",
      "Epoch 120/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1891 - mae: 0.3045 - val_loss: 0.3740 - val_mae: 0.4060\n",
      "Epoch 121/121\n",
      "331/331 [==============================] - 1s 3ms/step - loss: 0.1865 - mae: 0.3017 - val_loss: 0.4589 - val_mae: 0.4457\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "input_layer = keras.layers.Input(shape = (housing.data.shape[1],))\n",
    "\n",
    "hidden_layer1 = keras.layers.Dense(300)(input_layer)\n",
    "hidden_layer1 = keras.layers.BatchNormalization()(hidden_layer1)\n",
    "hidden_layer1 = keras.layers.Activation('relu')(hidden_layer1)\n",
    "\n",
    "hidden_layer2 = keras.layers.Dense(100)(hidden_layer1)\n",
    "hidden_layer2 = keras.layers.BatchNormalization()(hidden_layer2)\n",
    "hidden_layer2 = keras.layers.Activation('relu')(hidden_layer2)\n",
    "\n",
    "\n",
    "output_layer = keras.layers.Dense(1)(hidden_layer2)\n",
    "\n",
    "dnn_model = keras.Model(input_layer, output_layer)\n",
    "# optimizer= ['adam', 'rmsprop', 'sgd']\n",
    "# Or from tensorflow.keras.optimizers import SGD\n",
    "# optimizer = SGD(learning_rate=0.01, momentum=0.9)\n",
    "# loss= ['mean_squared_error', 'mean_absolute_error', 'huber_loss', 'mean_squared_logarithmic_error']\n",
    "# metrics=['mae', 'mse']\n",
    "dnn_model.compile(optimizer= 'adam',loss= 'mean_squared_error', metrics=['mae']) \n",
    "history = dnn_model.fit(X_train, y_train, epochs= 50, batch_size= 50, validation_data = (X_test, y_test)) #epochs= 40000 // (len(X_train) // 50), batch_size= 50, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9be98b7-91a4-4101-ae71-88fedb852704",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
